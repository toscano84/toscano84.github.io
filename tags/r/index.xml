<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Hugo Toscano</title>
    <link>https://toscano84.github.io/tags/r/</link>
    <description>Recent content in R on Hugo Toscano</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Mar 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://toscano84.github.io/tags/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Clustering the Pharmaceutical Industry Stocks</title>
      <link>https://toscano84.github.io/2019/03/clustering-the-pharmaceutical-industry-stocks/</link>
      <pubDate>Tue, 05 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://toscano84.github.io/2019/03/clustering-the-pharmaceutical-industry-stocks/</guid>
      <description>In this post I will use two of the most popular clustering methods, hierarchical clustering and k-means clustering, to analyse a data frame related to the financial variables of some pharmaceutical companies. Clustering is an unsupervised learning technique where we segment the data and identify meaningful groups that have similar characteristics. In our case, the goal will be to find these groups within the pharmaceutical companies data. Like we did in the previous posts we will start by loading the required packages to our analysis.</description>
    </item>
    
    <item>
      <title>Text Mining Crime and Punishment &amp; Anna Karenina: A Tidytext Approach</title>
      <link>https://toscano84.github.io/2018/12/text-mining-crime-and-punishment-and-anna-karenina-a-tidytext-approach/</link>
      <pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://toscano84.github.io/2018/12/text-mining-crime-and-punishment-and-anna-karenina-a-tidytext-approach/</guid>
      <description>Welcome to a new exciting post! Today I have decided to bring you text mining applied to two of my favorite novels: Crime and Punishment by Dostoyevsky and Anna Karenina by Tolstoy. We will use mainly the incredible tidytext package developed by Julia Silge and David Robinson. You can read more about this package in the book of the same authors Text Mining with R: A Tidytext Approach.
Let us start the analysis of “Crime and Punishment” and “Anna Karenina” by loading the required packages.</description>
    </item>
    
    <item>
      <title>A Leaflet approach to Coffee Chains: Starbucks versus Dunkin&#39; Donuts</title>
      <link>https://toscano84.github.io/2018/08/a-leaflet-approach-to-coffee-chains-starbucks-versus-dunkin-donuts/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://toscano84.github.io/2018/08/a-leaflet-approach-to-coffee-chains-starbucks-versus-dunkin-donuts/</guid>
      <description>This post talks about making interactive visualizations in R with leaflet(). In this example, I’ll map the USA locations of two of the biggest coffee chains, Starbucks and Dunkin’ Donuts. This package allows us to map data and play interactively with it. For instance, we can zoom in or zoom out to augment or diminish map details, respectively. We can add markers that signal the position of our data in the map and move the mouse cursor over to get information about it.</description>
    </item>
    
    <item>
      <title>Tuition costs and gdp per capita: A linear regression analysis</title>
      <link>https://toscano84.github.io/2018/07/linear-regression-in-r-a-simple-analysis/</link>
      <pubDate>Fri, 27 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://toscano84.github.io/2018/07/linear-regression-in-r-a-simple-analysis/</guid>
      <description>This post will explore with R one of the simplest approaches to predict a response of a quantitative nature. This approach is called Linear Regression.
I will use a simple Linear Regression to study whether there is any relationship between the gross domestic product (gdp) per capita of each state in the USA and its tuition costs. Therefore, our predictor will be the gdp per capita per state and our response will be the tuition costs per state.</description>
    </item>
    
    <item>
      <title>Using R to analyse the German Federal Election</title>
      <link>https://toscano84.github.io/2018/07/using-r-to-analyse-the-german-federal-election/</link>
      <pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://toscano84.github.io/2018/07/using-r-to-analyse-the-german-federal-election/</guid>
      <description>As the title of this post implies we will analyze, using the statistical programming language R, the German Federal Election which took place on 24 September of 2017. It will not be an exhaustive analysis of the results. I’m only interested in visualizing the share of the vote that each party represented in the Parliament (i.e. Bundestag) received in each one of the 16 States of Germany.
In order to make this visualization possible in R, loading the respective packages is the first step.</description>
    </item>
    
  </channel>
</rss>